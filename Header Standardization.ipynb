{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "63630403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "import json\n",
    "import re\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5b61d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, chunk_size=1000):\n",
    "    data = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            chunk = []\n",
    "            for i, line in enumerate(f):\n",
    "                chunk.append(json.loads(line.strip()))\n",
    "                if (i + 1) % chunk_size == 0:\n",
    "                    data.extend(chunk)\n",
    "                    chunk = []  \n",
    "            if chunk:\n",
    "                data.extend(chunk)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7c020137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe(data):\n",
    "    rows = []\n",
    "    labels = []\n",
    "\n",
    "    for document in data:\n",
    "        for row in document:\n",
    "            values = [cell['value'] for cell in row['values']]\n",
    "            rows.append(values)\n",
    "            labels.append(1 if row.get('type') == 'HEADERS' else 0)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return df, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7c43ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_features(df):\n",
    "    features = pd.DataFrame()\n",
    "\n",
    "    features['num_columns'] = df.apply(lambda row: sum(1 for cell in row if pd.notna(cell) and cell != ''), axis=1)\n",
    "    features['text_length'] = df.apply(lambda row: sum(len(str(cell)) for cell in row), axis=1)\n",
    "    features['digit_count'] = df.apply(lambda row: sum(char.isdigit() for cell in row for char in str(cell)), axis=1)\n",
    "    features['capitalization'] = df.apply(lambda row: sum(cell.isupper() for cell in row if isinstance(cell, str)), axis=1)\n",
    "    features['special_chars'] = df.apply(lambda row: sum(1 for cell in row if isinstance(cell, str) and re.search(r'[^a-zA-Z0-9\\s]', cell)), axis=1)\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c091ebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_class_imbalance(X, y):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_res, y_res = smote.fit_resample(X, y)\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "17af3ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y):\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, class_weight='balanced')\n",
    "    pipeline = Pipeline([('smote', SMOTE(random_state=42)), ('rf', model)])\n",
    "    pipeline.fit(X, y)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d5455db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_headers(documents, model):\n",
    "    predictions = []\n",
    "\n",
    "    for document in documents:\n",
    "        rows = [row['values'] for row in document]\n",
    "        df = pd.DataFrame([[cell['value'] for cell in row] for row in rows])\n",
    "\n",
    "        X_test = extract_text_features(df)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        for row, pred in zip(document, y_pred):\n",
    "            row['predicted_type'] = 'HEADER' if pred == 1 else 'NON-HEADER'\n",
    "\n",
    "        predictions.append(document)\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "032eafb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_test, y_test, model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Evaluation Results:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1886c86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and ready for future test data.\n",
      "Evaluation Results:\n",
      "Accuracy: 0.922562582372171\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92   2441662\n",
      "           1       0.92      0.93      0.92   2441662\n",
      "\n",
      "    accuracy                           0.92   4883324\n",
      "   macro avg       0.92      0.92      0.92   4883324\n",
      "weighted avg       0.92      0.92      0.92   4883324\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2234424  207238]\n",
      " [ 170914 2270748]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    training_file_path = 'C:\\\\Users\\\\Susma\\\\Documents\\\\Spacequant\\\\document-standardization-training-dataset\\\\document-standardization-training-dataset.txt'\n",
    "\n",
    "    training_data = load_data(training_file_path, chunk_size=1000)\n",
    "    df_train, labels = prepare_dataframe(training_data)\n",
    "\n",
    "    X_train = extract_text_features(df_train)\n",
    "\n",
    "    X_resampled, y_resampled = handle_class_imbalance(X_train, labels)\n",
    "\n",
    "    model = train_model(X_resampled, y_resampled)\n",
    "\n",
    "    joblib.dump(model, 'C:\\\\Users\\\\Susma\\\\Documents\\\\Spacequant\\\\document-standardization-training-dataset\\\\header_recognition_model.pkl')\n",
    "\n",
    "    print(\"Model trained and ready for future test data.\")\n",
    "\n",
    "    evaluate_model(X_resampled, y_resampled, model)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177b8be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future Testing: when test data is available, load and predict as below\n",
    "    # test_data = load_data(test_file_path)  \n",
    "    # predictions = predict_headers(test_data, model)\n",
    "    # for doc in predictions:\n",
    "    #     print(doc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a99a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
